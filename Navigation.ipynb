{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnityTimeOutException",
     "evalue": "Couldn't start socket communication because worker number 0 is still in use. You may need to manually close a previously opened environment or use a different worker number.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/udacity/drl/projects/p1_navigation/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0madd_UnityToExternalServicer_to_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_insecure_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[::]:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl-torch/lib/python3.9/site-packages/grpc/_server.py\u001b[0m in \u001b[0;36madd_insecure_port\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_insecure_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return _common.validate_port_binding_result(\n\u001b[0m\u001b[1;32m    962\u001b[0m             address, _add_insecure_port(self._state, _common.encode(address)))\n",
      "\u001b[0;32m~/miniconda3/envs/drl-torch/lib/python3.9/site-packages/grpc/_common.py\u001b[0m in \u001b[0;36mvalidate_port_binding_result\u001b[0;34m(address, port)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# is raising an exception to prevent further confusion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ERROR_MESSAGE_PORT_BINDING_FAILED\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to bind to address [::]:5005; set GRPC_VERBOSITY=debug environment variable to see detailed error message.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0e8247894881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./Banana_Linux_NoVis/Banana.x86_64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/udacity/drl/projects/p1_navigation/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/udacity/drl/projects/p1_navigation/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/udacity/drl/projects/p1_navigation/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             raise UnityTimeOutException(\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;34m\"Couldn't start socket communication because worker number {} is still in use. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m: Couldn't start socket communication because worker number 0 is still in use. You may need to manually close a previously opened environment or use a different worker number."
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_nam\n",
    "e=\"./Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-083ae890570e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get the default brain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbrain_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c6aa12bad02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# number of agents in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of agents:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-28eb1cd162fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;31m# get the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m                                          \u001b[0;31m# initialize the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# select an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/udacity/drl/projects/p1_navigation/unityagents/environment.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "source": [
    "---\n",
    "# My Implementation:\n",
    "## Agent and Replay Buffer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of a kernel restart, execute the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:unityagents:\n'Academy' started successfully!\nUnity Academy name: Academy\n        Number of Brains: 1\n        Number of External Brains : 1\n        Lesson number : 0\n        Reset Parameters :\n\t\t\nUnity brain name: BananaBrain\n        Number of Visual Observations (per agent): 0\n        Vector Observation space type: continuous\n        Vector Observation space size (per agent): 37\n        Number of stacked Vector Observation: 1\n        Vector Action space type: discrete\n        Vector Action space size (per agent): 4\n        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "import time\n",
    "import torch\n",
    "\n",
    "#################################\n",
    "#  Initialization:\n",
    "#################################\n",
    "\n",
    "# Define named tuple 'Experience'; you can use a dictionary alternatively\n",
    "Experience = namedtuple('Experience', ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "\n",
    "env = UnityEnvironment(file_name=\"./Banana_Linux_NoVis/Banana.x86_64\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One episode consists of 300 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from network_torch import QNetwork\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Available actions are:\n",
    "# 1. forward & backward\n",
    "# 2. left & right\n",
    "\n",
    "# State is given by 7 tuples of the form [1,2,3,4,5] and two additional scalars (cf. below):\n",
    "# Each of the tuples describes a ray which has been emanated along the angles: [20,90,160,45,135,70,110]\n",
    "# Or in ordered sequence: [20,45,70,90,110,135,160]\n",
    "# [Yellow Banana, Wall, Blue Banana, Agent, Distance]\n",
    "# Ex. [0,0,1,1,0,0.34] means there is\n",
    "# The last 2 numbers are the left/right turning velocity v_yaw and the forward/backward velocity v_lat of the agent: [v_yaw, v_lat]\n",
    "\n",
    "\n",
    "class TorchAgent():\n",
    "    def __init__(self, buffer_size, batch_size, action_size, gamma, learn_rate=0.0005):\n",
    "        if not batch_size < buffer_size:\n",
    "            raise Exception()\n",
    "\n",
    "        self.state_size = 37\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma\n",
    "        self.lr = learn_rate\n",
    "\n",
    "        # Initialize replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size, batch_size)\n",
    "        # Seed the random number generator\n",
    "        seed = 2#random.seed()\n",
    "        # QNetwork - We choose the simple network\n",
    "        self.local_net = QNetwork(self.state_size, self.action_size, seed).to(device)\n",
    "        self.target_net = QNetwork(self.state_size, self.action_size, seed=3).to(device)\n",
    "        self.hard_update_target_net()\n",
    "        self.optimizer = optim.Adam(self.local_net.parameters(), lr=self.lr)\n",
    "\n",
    "    # Let the agent learn from experience\n",
    "    def learn(self):\n",
    "        # Check if buffer is sufficiently full:\n",
    "        if not self.replay_buffer.buffer_usage():\n",
    "            return\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = self.replay_buffer.sample_from_buffer()\n",
    "\n",
    "        qs_local = self.local_net.forward(states)\n",
    "        qsa_local = qs_local[ torch.arange(self.batch_size, dtype=torch.long), actions.reshape(self.batch_size) ]\n",
    "        qsa_local = qsa_local.reshape( (self.batch_size, 1) )\n",
    "\n",
    "        qs_target = self.target_net.forward(next_states)\n",
    "        _, qsa_local_argmax_a = torch.max(qs_local, dim=1)\n",
    "        qsa_target = qs_target[ torch.arange(self.batch_size, dtype=torch.long), qsa_local_argmax_a.reshape(self.batch_size) ]\n",
    "\n",
    "        qsa_target = qsa_target * (1 - dones.reshape(self.batch_size))\n",
    "        qsa_target = qsa_target.reshape((self.batch_size,1))\n",
    "        TD_target = rewards + self.gamma * qsa_target\n",
    "\n",
    "        loss = F.mse_loss(qsa_local, TD_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        \"\"\"\n",
    "        Q_targets_next = self.target_net(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.local_net(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \"\"\"\n",
    "\n",
    "        self.soft_update_target_net()\n",
    "\n",
    "\n",
    "    # Take action according to epsilon-greedy-policy:\n",
    "    def action(self, state, epsilon=0.02):\n",
    "        \n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.local_net.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_net.forward(state)\n",
    "        self.local_net.train()\n",
    "\n",
    "        if random.random() < epsilon:\n",
    "            return random.randrange(0, self.action_size)\n",
    "        else:\n",
    "            #print(action_values.cpu().data.numpy())\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "\n",
    "    def random_action(self):\n",
    "        return random.randrange(0, self.action_size)\n",
    "\n",
    "    # Copy weights from short-term model to long-term model (soft update)\n",
    "    def soft_update_target_net(self, tau=0.001):\n",
    "        for t, l in zip(self.target_net.parameters(), self.local_net.parameters() ):\n",
    "            t.data.copy_( (1-tau)*t.data + tau*l.data )\n",
    "\n",
    "    def hard_update_target_net(self):\n",
    "        self.soft_update_target_net( tau=1.0 )\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        filepath = os.path.join(path, \"ddqn_weights_latest.pth\")\n",
    "        print(\"Loading network weights from\", filepath)\n",
    "        self.local_net.load_state_dict(torch.load(filepath, map_location=lambda storage, loc: storage))\n",
    "        self.hard_update_target_net()\n",
    "\n",
    "    def save_weights(self, path):\n",
    "        filepath = os.path.join(path, \"ddqn_weights_latest.pth\")\n",
    "        print(\"Saving target network weights to\", filepath)\n",
    "        torch.save(self.target_net.state_dict(), filepath) \n",
    "\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "    # Insert experience into memory\n",
    "    def insert_into_buffer(self, experience):\n",
    "        self.replay_buffer.append(experience)\n",
    "\n",
    "    # Randomly sample memory\n",
    "    def sample_from_buffer(self):\n",
    "        # Sample experience batch from experience buffer\n",
    "        batch = random.sample(self.replay_buffer, self.batch_size)\n",
    "        \n",
    "        # Reorder experience batch such that we have a batch of states, a batch of actions, a batch of rewards, etc.\n",
    "        state = torch.from_numpy( np.vstack( [exp.state for exp in batch if exp is not None] )).float().to(device)\n",
    "        action = torch.from_numpy( np.vstack( [exp.action for exp in batch if exp is not None] )).long().to(device)\n",
    "        reward = torch.from_numpy( np.vstack( [exp.reward for exp in batch if exp is not None] )).float().to(device)\n",
    "        state_next = torch.from_numpy( np.vstack( [exp.next_state for exp in batch if exp is not None] ) ).float().to(device)\n",
    "        done = torch.from_numpy( np.vstack( [exp.done for exp in batch if exp is not None] ).astype(np.uint8) ).float().to(device)\n",
    "\n",
    "        return state, action, reward, state_next, done\n",
    "\n",
    "    # Get length of memory\n",
    "    def buffer_usage(self):\n",
    "        return len(self.replay_buffer) > self.batch_size\n"
   ]
  },
  {
   "source": [
    "## Network Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, units_fc1 = 64, units_fc2 = 64):\n",
    "        super(QNetwork, self).__init__()\n",
    "        \n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size, units_fc1)\n",
    "        self.fc2 = nn.Linear(units_fc1, units_fc2)\n",
    "        self.fc3 = nn.Linear(units_fc2, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu( self.fc1(state) )\n",
    "        x = F.relu( self.fc2(x) )\n",
    "        action = self.fc3( x )\n",
    "        return action"
   ]
  },
  {
   "source": [
    "## Main Training Loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agent_torch import TorchAgent\n",
    "agent = TorchAgent(buffer_size=100000, batch_size=64, action_size=4, gamma=0.99)\n",
    "\n",
    "#agent.load_weights(\"./checkpoints\")\n",
    "\n",
    "def training(n_episodes=500):\n",
    "    eps = 1.\n",
    "    eps_end = 0.02\n",
    "    eps_decay = 0.995\n",
    "    learning_period = 4\n",
    "\n",
    "    score_list = []   # Score is NOT the discounted reward but the final 'Banana Score' of the game\n",
    "    score_trailing_list = deque(maxlen=100)\n",
    "    score_trailing_avg_list = []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        ticks = 0\n",
    "        score = 0\n",
    "\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  # Reset the environment\n",
    "        state = env_info.vector_observations[0]            # Get the current state\n",
    "        \n",
    "        start = time.time()\n",
    "        while True:\n",
    "            # Select action according to policy:\n",
    "            action = agent.action(state, epsilon=eps)\n",
    "            #print(\"[Episode {}, Time {}] Action taken: {}\".format(episode, time, action))\n",
    "            # Take action and record the reward and the successive state\n",
    "            env_info = env.step(action)[brain_name]\n",
    "\n",
    "            reward = env_info.rewards[0]\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            done = env_info.local_done[0]\n",
    "\n",
    "            # Add experience to the agent's replay buffer:\n",
    "            exp = Experience(state, action, reward, next_state, done)\n",
    "            agent.replay_buffer.insert_into_buffer( exp )\n",
    "\n",
    "            if ticks % learning_period == 0:\n",
    "                agent.learn()\n",
    "\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            if done is True:\n",
    "                break\n",
    "\n",
    "            ticks += 1\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        score_list.append(score)\n",
    "        score_trailing_list.append(score)\n",
    "\n",
    "        score_trailing_avg = np.mean(score_trailing_list)\n",
    "        score_trailing_avg_list.append(score_trailing_avg)\n",
    "        \n",
    "        print(\"***********************************************\")\n",
    "        print(\"Score of episode {}: {}\".format(episode, score))\n",
    "        print(\"Trailing avg. score: {:.2f}\".format(score_trailing_avg))\n",
    "        print(\"Greedy epsilon used: {:.2f}\".format(eps))\n",
    "        print(\"Time consumed: {:.2f} s\".format(end-start))\n",
    "        print(\"***********************************************\")\n",
    "\n",
    "        if score_trailing_avg >= 13.0:\n",
    "            print(\"===============================================\")\n",
    "            print(\"Challenge solved at episode {}\".format(episode))\n",
    "            print(\"===============================================\")\n",
    "\n",
    "        eps = max(eps*eps_decay, eps_end)\n",
    "        episode += 1\n",
    "\n",
    "        agent.save_weights(\"./checkpoints_torch\")\n",
    "\n",
    "    return score_list, score_trailing_avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "llenge solved at episode 1950\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1951: 17.0\n",
      "Trailing avg. score: 15.74\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.05 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1951\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1952: 18.0\n",
      "Trailing avg. score: 15.73\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.02 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1952\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1953: 15.0\n",
      "Trailing avg. score: 15.70\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.00 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1953\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1954: 21.0\n",
      "Trailing avg. score: 15.71\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.06 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1954\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1955: 19.0\n",
      "Trailing avg. score: 15.74\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.08 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1955\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1956: 12.0\n",
      "Trailing avg. score: 15.73\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.07 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1956\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1957: 17.0\n",
      "Trailing avg. score: 15.83\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.99 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1957\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1958: 12.0\n",
      "Trailing avg. score: 15.78\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.99 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1958\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1959: 16.0\n",
      "Trailing avg. score: 15.75\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1959\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1960: 14.0\n",
      "Trailing avg. score: 15.71\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.98 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1960\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1961: 17.0\n",
      "Trailing avg. score: 15.69\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1961\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1962: 11.0\n",
      "Trailing avg. score: 15.67\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.04 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1962\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1963: 15.0\n",
      "Trailing avg. score: 15.67\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.06 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1963\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1964: 18.0\n",
      "Trailing avg. score: 15.74\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.06 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1964\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1965: 19.0\n",
      "Trailing avg. score: 15.79\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.07 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1965\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1966: 13.0\n",
      "Trailing avg. score: 15.71\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.05 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1966\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1967: 20.0\n",
      "Trailing avg. score: 15.75\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.05 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1967\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1968: 15.0\n",
      "Trailing avg. score: 15.77\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.00 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1968\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1969: 22.0\n",
      "Trailing avg. score: 15.85\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.03 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1969\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1970: 17.0\n",
      "Trailing avg. score: 15.86\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.02 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1970\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1971: 11.0\n",
      "Trailing avg. score: 15.82\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.99 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1971\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1972: 20.0\n",
      "Trailing avg. score: 15.88\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.04 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1972\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1973: 21.0\n",
      "Trailing avg. score: 15.89\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.03 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1973\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1974: 15.0\n",
      "Trailing avg. score: 15.87\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.02 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1974\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1975: 17.0\n",
      "Trailing avg. score: 15.85\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.06 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1975\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1976: 21.0\n",
      "Trailing avg. score: 15.93\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.19 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1976\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1977: 14.0\n",
      "Trailing avg. score: 15.93\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.14 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1977\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1978: 17.0\n",
      "Trailing avg. score: 15.98\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.07 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1978\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1979: 18.0\n",
      "Trailing avg. score: 16.02\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.02 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1979\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1980: 20.0\n",
      "Trailing avg. score: 16.06\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.00 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1980\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1981: 23.0\n",
      "Trailing avg. score: 16.15\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1981\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1982: 17.0\n",
      "Trailing avg. score: 16.21\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.00 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1982\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1983: 21.0\n",
      "Trailing avg. score: 16.25\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1983\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1984: 16.0\n",
      "Trailing avg. score: 16.30\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.06 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1984\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1985: 17.0\n",
      "Trailing avg. score: 16.31\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.97 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1985\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1986: 17.0\n",
      "Trailing avg. score: 16.33\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.04 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1986\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1987: 20.0\n",
      "Trailing avg. score: 16.32\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.02 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1987\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1988: 14.0\n",
      "Trailing avg. score: 16.28\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1988\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1989: 14.0\n",
      "Trailing avg. score: 16.24\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.04 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1989\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1990: 18.0\n",
      "Trailing avg. score: 16.31\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.07 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1990\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1991: 17.0\n",
      "Trailing avg. score: 16.30\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 0.99 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1991\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1992: 10.0\n",
      "Trailing avg. score: 16.27\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.03 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1992\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1993: 11.0\n",
      "Trailing avg. score: 16.26\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.04 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1993\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1994: 11.0\n",
      "Trailing avg. score: 16.21\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.10 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1994\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1995: 14.0\n",
      "Trailing avg. score: 16.17\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.11 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1995\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1996: 16.0\n",
      "Trailing avg. score: 16.23\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.03 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1996\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1997: 14.0\n",
      "Trailing avg. score: 16.23\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.00 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1997\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1998: 15.0\n",
      "Trailing avg. score: 16.23\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.07 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1998\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n",
      "***********************************************\n",
      "Score of episode 1999: 17.0\n",
      "Trailing avg. score: 16.27\n",
      "Greedy epsilon used: 0.02\n",
      "Time consumed: 1.01 s\n",
      "***********************************************\n",
      "===============================================\n",
      "Challenge solved at episode 1999\n",
      "===============================================\n",
      "Saving target network weights to ./checkpoints_torch/ddqn_weights_latest.pth\n"
     ]
    }
   ],
   "source": [
    "score_list, score_trailing_avg_list = training(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 382.603125 262.19625\" width=\"382.603125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-18T19:42:30.382940</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 382.603125 262.19625 \nL 382.603125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 224.64 \nL 375.403125 224.64 \nL 375.403125 7.2 \nL 40.603125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m335d57d810\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.821307\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.640057 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.694034\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(107.150284 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.566761\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(168.023011 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.439489\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(228.895739 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.312216\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(289.768466 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"360.184943\" xlink:href=\"#m335d57d810\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(350.641193 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Episode # -->\n     <g transform=\"translate(182.586719 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 51.125 44 \nL 36.921875 44 \nL 32.8125 27.6875 \nL 47.125 27.6875 \nz\nM 43.796875 71.78125 \nL 38.71875 51.515625 \nL 52.984375 51.515625 \nL 58.109375 71.78125 \nL 65.921875 71.78125 \nL 60.890625 51.515625 \nL 76.125 51.515625 \nL 76.125 44 \nL 58.984375 44 \nL 54.984375 27.6875 \nL 70.515625 27.6875 \nL 70.515625 20.21875 \nL 53.078125 20.21875 \nL 48 0 \nL 40.1875 0 \nL 45.21875 20.21875 \nL 30.90625 20.21875 \nL 25.875 0 \nL 18.015625 0 \nL 23.09375 20.21875 \nL 7.71875 20.21875 \nL 7.71875 27.6875 \nL 24.90625 27.6875 \nL 29 44 \nL 13.28125 44 \nL 13.28125 51.515625 \nL 30.90625 51.515625 \nL 35.890625 71.78125 \nz\n\" id=\"DejaVuSans-35\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"154.443359\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"206.542969\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"267.724609\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"331.201172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"392.724609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"424.511719\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m75bb47d86b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m75bb47d86b\" y=\"196.786116\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 200.585334)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m75bb47d86b\" y=\"151.860496\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(27.240625 155.659715)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m75bb47d86b\" y=\"106.934876\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 110.734095)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m75bb47d86b\" y=\"62.009256\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(20.878125 65.808475)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m75bb47d86b\" y=\"17.083636\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(20.878125 20.882855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Score -->\n     <g transform=\"translate(14.798438 129.922344)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"118.457031\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"179.638672\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"218.501953\" xlink:href=\"#DejaVuSans-101\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 224.64 \nL 40.603125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 375.403125 224.64 \nL 375.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 224.64 \nL 375.403125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 7.2 \nL 375.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pe61f54c067)\" d=\"M 55.821307 187.800992 \nL 56.430034 205.77124 \nL 57.038761 205.77124 \nL 57.647489 196.786116 \nL 58.256216 196.786116 \nL 58.864943 205.77124 \nL 59.47367 205.77124 \nL 60.082398 187.800992 \nL 60.691125 196.786116 \nL 61.299852 196.786116 \nL 61.90858 205.77124 \nL 62.517307 187.800992 \nL 63.126034 196.786116 \nL 63.734761 214.756364 \nL 64.343489 196.786116 \nL 65.560943 196.786116 \nL 66.16967 187.800992 \nL 67.387125 205.77124 \nL 67.995852 178.815868 \nL 68.60458 196.786116 \nL 69.213307 196.786116 \nL 69.822034 169.830744 \nL 70.430761 196.786116 \nL 71.039489 187.800992 \nL 71.648216 205.77124 \nL 72.256943 205.77124 \nL 72.86567 187.800992 \nL 74.083125 187.800992 \nL 74.691852 178.815868 \nL 75.30058 178.815868 \nL 75.909307 196.786116 \nL 76.518034 169.830744 \nL 77.126761 187.800992 \nL 77.735489 178.815868 \nL 78.344216 187.800992 \nL 78.952943 187.800992 \nL 79.56167 196.786116 \nL 80.170398 196.786116 \nL 81.387852 178.815868 \nL 81.99658 196.786116 \nL 82.605307 178.815868 \nL 83.214034 187.800992 \nL 83.822761 187.800992 \nL 84.431489 196.786116 \nL 85.040216 187.800992 \nL 85.648943 187.800992 \nL 86.25767 160.84562 \nL 86.866398 151.860496 \nL 88.083852 187.800992 \nL 89.301307 187.800992 \nL 89.910034 196.786116 \nL 90.518761 196.786116 \nL 91.127489 187.800992 \nL 91.736216 187.800992 \nL 92.344943 178.815868 \nL 92.95367 187.800992 \nL 93.562398 187.800992 \nL 94.171125 169.830744 \nL 94.779852 178.815868 \nL 95.38858 169.830744 \nL 95.997307 169.830744 \nL 96.606034 196.786116 \nL 97.214761 205.77124 \nL 97.823489 178.815868 \nL 98.432216 178.815868 \nL 99.040943 187.800992 \nL 99.64967 187.800992 \nL 100.258398 196.786116 \nL 100.867125 169.830744 \nL 101.475852 151.860496 \nL 102.693307 151.860496 \nL 103.302034 196.786116 \nL 103.910761 160.84562 \nL 104.519489 196.786116 \nL 105.128216 205.77124 \nL 105.736943 160.84562 \nL 106.34567 160.84562 \nL 106.954398 178.815868 \nL 107.563125 169.830744 \nL 108.171852 169.830744 \nL 109.389307 187.800992 \nL 109.998034 178.815868 \nL 110.606761 151.860496 \nL 111.215489 160.84562 \nL 111.824216 178.815868 \nL 112.432943 178.815868 \nL 113.04167 160.84562 \nL 113.650398 169.830744 \nL 114.259125 124.905124 \nL 114.867852 151.860496 \nL 115.47658 169.830744 \nL 116.085307 142.875372 \nL 116.694034 133.890248 \nL 117.302761 196.786116 \nL 118.520216 160.84562 \nL 119.128943 151.860496 \nL 119.73767 178.815868 \nL 120.346398 151.860496 \nL 120.955125 160.84562 \nL 121.563852 187.800992 \nL 122.17258 133.890248 \nL 122.781307 124.905124 \nL 123.998761 160.84562 \nL 124.607489 142.875372 \nL 125.216216 133.890248 \nL 125.824943 178.815868 \nL 126.43367 133.890248 \nL 127.042398 142.875372 \nL 127.651125 142.875372 \nL 128.259852 160.84562 \nL 128.86858 142.875372 \nL 129.477307 142.875372 \nL 130.086034 133.890248 \nL 131.303489 133.890248 \nL 131.912216 160.84562 \nL 132.520943 169.830744 \nL 133.12967 169.830744 \nL 133.738398 142.875372 \nL 134.347125 79.979504 \nL 134.955852 160.84562 \nL 135.56458 178.815868 \nL 136.173307 160.84562 \nL 136.782034 160.84562 \nL 137.390761 133.890248 \nL 137.999489 124.905124 \nL 138.608216 133.890248 \nL 139.216943 178.815868 \nL 139.82567 169.830744 \nL 140.434398 169.830744 \nL 141.043125 178.815868 \nL 141.651852 178.815868 \nL 142.26058 124.905124 \nL 142.869307 160.84562 \nL 144.086761 142.875372 \nL 144.695489 196.786116 \nL 145.304216 133.890248 \nL 145.912943 151.860496 \nL 146.52167 160.84562 \nL 147.130398 142.875372 \nL 147.739125 160.84562 \nL 148.347852 124.905124 \nL 148.95658 169.830744 \nL 149.565307 151.860496 \nL 150.174034 142.875372 \nL 150.782761 169.830744 \nL 151.391489 169.830744 \nL 152.000216 151.860496 \nL 152.608943 124.905124 \nL 153.21767 151.860496 \nL 153.826398 106.934876 \nL 154.435125 142.875372 \nL 155.043852 142.875372 \nL 156.261307 124.905124 \nL 156.870034 142.875372 \nL 157.478761 151.860496 \nL 158.087489 133.890248 \nL 158.696216 178.815868 \nL 159.304943 133.890248 \nL 159.91367 115.92 \nL 160.522398 133.890248 \nL 161.131125 160.84562 \nL 161.739852 142.875372 \nL 162.34858 106.934876 \nL 162.957307 142.875372 \nL 163.566034 133.890248 \nL 164.174761 142.875372 \nL 164.783489 124.905124 \nL 165.392216 97.949752 \nL 166.000943 106.934876 \nL 166.60967 106.934876 \nL 167.218398 97.949752 \nL 167.827125 115.92 \nL 168.435852 142.875372 \nL 169.04458 97.949752 \nL 169.653307 169.830744 \nL 170.262034 160.84562 \nL 170.870761 106.934876 \nL 171.479489 88.964628 \nL 172.088216 124.905124 \nL 172.696943 151.860496 \nL 173.30567 124.905124 \nL 173.914398 151.860496 \nL 174.523125 151.860496 \nL 175.131852 142.875372 \nL 175.74058 151.860496 \nL 176.349307 133.890248 \nL 176.958034 178.815868 \nL 177.566761 97.949752 \nL 178.175489 187.800992 \nL 178.784216 124.905124 \nL 179.392943 124.905124 \nL 180.00167 115.92 \nL 180.610398 124.905124 \nL 181.219125 97.949752 \nL 181.827852 142.875372 \nL 182.43658 151.860496 \nL 183.045307 70.99438 \nL 183.654034 151.860496 \nL 184.262761 106.934876 \nL 184.871489 178.815868 \nL 185.480216 133.890248 \nL 186.088943 151.860496 \nL 186.69767 115.92 \nL 187.306398 133.890248 \nL 187.915125 142.875372 \nL 188.523852 160.84562 \nL 189.13258 142.875372 \nL 189.741307 169.830744 \nL 190.350034 115.92 \nL 190.958761 151.860496 \nL 191.567489 115.92 \nL 192.176216 97.949752 \nL 192.784943 160.84562 \nL 193.39367 142.875372 \nL 194.002398 133.890248 \nL 194.611125 70.99438 \nL 195.219852 88.964628 \nL 195.82858 160.84562 \nL 196.437307 178.815868 \nL 197.046034 124.905124 \nL 197.654761 151.860496 \nL 198.263489 106.934876 \nL 198.872216 97.949752 \nL 199.480943 133.890248 \nL 200.08967 115.92 \nL 200.698398 79.979504 \nL 201.307125 106.934876 \nL 201.915852 124.905124 \nL 202.52458 124.905124 \nL 203.133307 79.979504 \nL 203.742034 79.979504 \nL 204.350761 160.84562 \nL 204.959489 97.949752 \nL 205.568216 160.84562 \nL 206.176943 88.964628 \nL 206.78567 70.99438 \nL 207.394398 97.949752 \nL 208.003125 133.890248 \nL 208.611852 97.949752 \nL 209.22058 88.964628 \nL 209.829307 124.905124 \nL 210.438034 151.860496 \nL 211.046761 106.934876 \nL 211.655489 79.979504 \nL 212.872943 133.890248 \nL 213.48167 133.890248 \nL 214.090398 106.934876 \nL 214.699125 62.009256 \nL 215.307852 124.905124 \nL 215.91658 115.92 \nL 216.525307 124.905124 \nL 217.134034 169.830744 \nL 217.742761 79.979504 \nL 218.351489 124.905124 \nL 218.960216 133.890248 \nL 219.568943 133.890248 \nL 220.17767 160.84562 \nL 220.786398 124.905124 \nL 221.395125 124.905124 \nL 222.003852 106.934876 \nL 222.61258 79.979504 \nL 223.221307 142.875372 \nL 223.830034 133.890248 \nL 224.438761 115.92 \nL 225.047489 133.890248 \nL 225.656216 106.934876 \nL 226.264943 142.875372 \nL 226.87367 133.890248 \nL 227.482398 169.830744 \nL 228.091125 106.934876 \nL 228.699852 97.949752 \nL 229.30858 79.979504 \nL 229.917307 106.934876 \nL 230.526034 115.92 \nL 231.134761 142.875372 \nL 231.743489 115.92 \nL 232.352216 115.92 \nL 232.960943 88.964628 \nL 233.56967 133.890248 \nL 234.178398 70.99438 \nL 234.787125 79.979504 \nL 235.395852 70.99438 \nL 236.00458 97.949752 \nL 236.613307 106.934876 \nL 237.222034 88.964628 \nL 237.830761 133.890248 \nL 238.439489 79.979504 \nL 239.048216 106.934876 \nL 239.656943 97.949752 \nL 240.26567 106.934876 \nL 240.874398 97.949752 \nL 241.483125 178.815868 \nL 242.091852 115.92 \nL 242.70058 169.830744 \nL 243.309307 106.934876 \nL 243.918034 133.890248 \nL 244.526761 97.949752 \nL 245.135489 124.905124 \nL 245.744216 88.964628 \nL 246.352943 79.979504 \nL 246.96167 124.905124 \nL 247.570398 88.964628 \nL 248.179125 124.905124 \nL 248.787852 151.860496 \nL 249.39658 115.92 \nL 250.005307 106.934876 \nL 250.614034 124.905124 \nL 251.222761 88.964628 \nL 251.831489 142.875372 \nL 252.440216 97.949752 \nL 253.65767 133.890248 \nL 254.266398 97.949752 \nL 254.875125 124.905124 \nL 255.483852 70.99438 \nL 256.09258 124.905124 \nL 256.701307 142.875372 \nL 257.310034 115.92 \nL 257.918761 79.979504 \nL 258.527489 88.964628 \nL 259.136216 79.979504 \nL 259.744943 97.949752 \nL 260.35367 106.934876 \nL 260.962398 106.934876 \nL 261.571125 124.905124 \nL 262.179852 97.949752 \nL 262.78858 115.92 \nL 263.397307 160.84562 \nL 264.006034 106.934876 \nL 264.614761 133.890248 \nL 265.223489 115.92 \nL 265.832216 88.964628 \nL 266.440943 115.92 \nL 267.04967 70.99438 \nL 267.658398 115.92 \nL 268.267125 115.92 \nL 268.875852 53.024132 \nL 269.48458 70.99438 \nL 270.093307 79.979504 \nL 270.702034 53.024132 \nL 271.310761 133.890248 \nL 271.919489 106.934876 \nL 272.528216 115.92 \nL 273.136943 106.934876 \nL 273.74567 160.84562 \nL 274.354398 115.92 \nL 274.963125 88.964628 \nL 275.571852 88.964628 \nL 276.18058 70.99438 \nL 276.789307 115.92 \nL 278.006761 115.92 \nL 278.615489 88.964628 \nL 279.224216 124.905124 \nL 279.832943 88.964628 \nL 281.050398 70.99438 \nL 281.659125 97.949752 \nL 282.267852 178.815868 \nL 282.87658 62.009256 \nL 283.485307 133.890248 \nL 284.094034 79.979504 \nL 284.702761 97.949752 \nL 285.311489 79.979504 \nL 285.920216 79.979504 \nL 286.528943 26.06876 \nL 287.13767 124.905124 \nL 288.355125 142.875372 \nL 288.963852 62.009256 \nL 289.57258 106.934876 \nL 290.181307 70.99438 \nL 290.790034 142.875372 \nL 291.398761 160.84562 \nL 292.007489 62.009256 \nL 292.616216 115.92 \nL 293.224943 79.979504 \nL 293.83367 88.964628 \nL 294.442398 70.99438 \nL 295.051125 70.99438 \nL 295.659852 115.92 \nL 296.26858 44.039008 \nL 296.877307 88.964628 \nL 297.486034 97.949752 \nL 298.094761 53.024132 \nL 298.703489 115.92 \nL 299.312216 115.92 \nL 299.920943 79.979504 \nL 300.52967 115.92 \nL 301.138398 124.905124 \nL 302.355852 70.99438 \nL 302.96458 53.024132 \nL 303.573307 70.99438 \nL 304.182034 53.024132 \nL 304.790761 160.84562 \nL 305.399489 115.92 \nL 306.008216 151.860496 \nL 306.616943 97.949752 \nL 307.22567 106.934876 \nL 307.834398 106.934876 \nL 308.443125 62.009256 \nL 309.051852 79.979504 \nL 309.66058 53.024132 \nL 310.878034 124.905124 \nL 311.486761 106.934876 \nL 312.095489 97.949752 \nL 312.704216 115.92 \nL 313.312943 115.92 \nL 313.92167 53.024132 \nL 314.530398 79.979504 \nL 315.139125 62.009256 \nL 315.747852 26.06876 \nL 316.35658 53.024132 \nL 316.965307 88.964628 \nL 317.574034 70.99438 \nL 318.182761 88.964628 \nL 318.791489 70.99438 \nL 319.400216 44.039008 \nL 320.008943 97.949752 \nL 320.61767 79.979504 \nL 321.226398 44.039008 \nL 321.835125 115.92 \nL 322.443852 106.934876 \nL 323.05258 79.979504 \nL 323.661307 44.039008 \nL 324.270034 106.934876 \nL 324.878761 70.99438 \nL 325.487489 88.964628 \nL 326.096216 70.99438 \nL 326.704943 169.830744 \nL 327.31367 151.860496 \nL 328.531125 17.083636 \nL 329.139852 115.92 \nL 329.74858 35.053884 \nL 330.357307 79.979504 \nL 330.966034 62.009256 \nL 331.574761 106.934876 \nL 332.183489 35.053884 \nL 332.792216 124.905124 \nL 333.400943 70.99438 \nL 334.00967 35.053884 \nL 334.618398 106.934876 \nL 335.227125 196.786116 \nL 335.835852 88.964628 \nL 336.44458 53.024132 \nL 337.053307 62.009256 \nL 337.662034 106.934876 \nL 338.270761 53.024132 \nL 338.879489 26.06876 \nL 339.488216 106.934876 \nL 340.096943 62.009256 \nL 340.70567 70.99438 \nL 341.314398 142.875372 \nL 341.923125 178.815868 \nL 342.531852 88.964628 \nL 343.14058 106.934876 \nL 343.749307 70.99438 \nL 344.358034 106.934876 \nL 344.966761 44.039008 \nL 346.184216 115.92 \nL 346.792943 106.934876 \nL 347.40167 115.92 \nL 348.010398 62.009256 \nL 348.619125 169.830744 \nL 349.227852 44.039008 \nL 349.83658 79.979504 \nL 350.445307 53.024132 \nL 351.054034 106.934876 \nL 351.662761 97.949752 \nL 352.271489 44.039008 \nL 352.880216 106.934876 \nL 353.488943 133.890248 \nL 354.09767 79.979504 \nL 354.706398 62.009256 \nL 355.315125 62.009256 \nL 355.923852 70.99438 \nL 356.53258 53.024132 \nL 357.141307 79.979504 \nL 357.750034 79.979504 \nL 358.358761 70.99438 \nL 358.967489 124.905124 \nL 359.576216 53.024132 \nL 359.576216 53.024132 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"LineCollection_1\">\n    <path clip-path=\"url(#pe61f54c067)\" d=\"M 55.821307 79.979504 \nL 360.184943 79.979504 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pe61f54c067)\" d=\"M 55.821307 187.800992 \nL 56.430034 196.786116 \nL 57.038761 199.781157 \nL 57.647489 199.032397 \nL 58.256216 198.58314 \nL 58.864943 199.781157 \nL 59.47367 200.636883 \nL 60.082398 199.032397 \nL 61.299852 198.58314 \nL 61.90858 199.236604 \nL 62.517307 198.283636 \nL 63.126034 198.168442 \nL 63.734761 199.353294 \nL 65.560943 198.900263 \nL 66.16967 198.283636 \nL 66.778398 198.204819 \nL 67.387125 198.58314 \nL 67.995852 197.641842 \nL 69.213307 197.567431 \nL 69.822034 196.411736 \nL 70.430761 196.426711 \nL 71.039489 196.094952 \nL 72.256943 196.786116 \nL 74.083125 195.916588 \nL 75.30058 194.88018 \nL 75.909307 194.936237 \nL 76.518034 194.218937 \nL 77.126761 194.040661 \nL 77.735489 193.62918 \nL 78.952943 193.330299 \nL 80.170398 193.498875 \nL 80.779125 193.363211 \nL 81.387852 193.024901 \nL 81.99658 193.110383 \nL 82.605307 192.792727 \nL 83.822761 192.580313 \nL 84.431489 192.667934 \nL 85.648943 192.473256 \nL 87.475125 190.683013 \nL 89.301307 190.528619 \nL 90.518761 190.744394 \nL 91.736216 190.646281 \nL 92.344943 190.45234 \nL 93.562398 190.36817 \nL 94.171125 190.047273 \nL 94.779852 189.874482 \nL 95.997307 189.276161 \nL 96.606034 189.386602 \nL 97.214761 189.62406 \nL 98.432216 189.319604 \nL 99.64967 189.277998 \nL 100.258398 189.379459 \nL 100.867125 189.11881 \nL 102.693307 187.685798 \nL 103.302034 187.800992 \nL 103.910761 187.46405 \nL 105.128216 187.800992 \nL 106.34567 187.159197 \nL 107.563125 186.860688 \nL 108.78058 186.575748 \nL 109.998034 186.50314 \nL 111.215489 185.847704 \nL 112.432943 185.69809 \nL 113.650398 185.273926 \nL 114.259125 184.651567 \nL 114.867852 184.316964 \nL 115.47658 184.170639 \nL 116.694034 183.218579 \nL 117.302761 183.128727 \nL 118.520216 182.499769 \nL 119.128943 182.050512 \nL 119.73767 181.780959 \nL 120.346398 181.241851 \nL 120.955125 180.972298 \nL 121.563852 180.882446 \nL 122.17258 180.253488 \nL 122.781307 179.444826 \nL 123.998761 178.636165 \nL 125.216216 177.288397 \nL 125.824943 177.108694 \nL 126.43367 176.479736 \nL 129.477307 174.143603 \nL 130.086034 173.514645 \nL 130.694761 173.15524 \nL 131.303489 172.526281 \nL 132.520943 171.897322 \nL 133.738398 171.088661 \nL 134.347125 170.010446 \nL 134.955852 169.740893 \nL 135.56458 169.740893 \nL 136.173307 169.56119 \nL 137.390761 168.84238 \nL 137.999489 168.213421 \nL 138.608216 167.764165 \nL 139.82567 167.494612 \nL 141.043125 167.045355 \nL 141.651852 166.955504 \nL 142.26058 166.416397 \nL 144.086761 165.338182 \nL 144.695489 165.428033 \nL 145.304216 164.799074 \nL 146.52167 164.170116 \nL 147.130398 163.990413 \nL 147.739125 164.080264 \nL 148.347852 163.631008 \nL 148.95658 163.451306 \nL 152.000216 161.744132 \nL 152.608943 161.115174 \nL 153.21767 160.84562 \nL 153.826398 160.036959 \nL 154.435125 159.587702 \nL 155.043852 159.318149 \nL 156.261307 158.419636 \nL 156.870034 158.150083 \nL 157.478761 157.700826 \nL 158.087489 156.982017 \nL 158.696216 156.982017 \nL 159.304943 156.53276 \nL 159.91367 155.81395 \nL 160.522398 155.274843 \nL 162.34858 154.196628 \nL 163.566034 153.927074 \nL 164.174761 153.387967 \nL 164.783489 153.028562 \nL 166.000943 151.051835 \nL 167.218398 149.883769 \nL 167.827125 149.25481 \nL 168.435852 148.985256 \nL 169.04458 148.266446 \nL 169.653307 148.176595 \nL 170.262034 147.907041 \nL 171.479489 146.559273 \nL 173.30567 145.391207 \nL 174.523125 145.121653 \nL 175.131852 145.301355 \nL 175.74058 145.301355 \nL 176.349307 144.94195 \nL 176.958034 145.301355 \nL 177.566761 144.94195 \nL 178.175489 144.852099 \nL 178.784216 144.312992 \nL 180.00167 143.594182 \nL 181.219125 142.515967 \nL 181.827852 142.336264 \nL 182.43658 141.97686 \nL 183.045307 141.347901 \nL 183.654034 141.617455 \nL 184.262761 141.25805 \nL 184.871489 141.437752 \nL 185.480216 141.347901 \nL 186.088943 141.527603 \nL 186.69767 140.898645 \nL 187.915125 140.898645 \nL 188.523852 141.078347 \nL 189.13258 140.898645 \nL 189.741307 141.168198 \nL 190.350034 140.898645 \nL 190.958761 141.078347 \nL 191.567489 140.898645 \nL 192.176216 140.53924 \nL 192.784943 140.53924 \nL 194.002398 139.910281 \nL 194.611125 139.191471 \nL 195.82858 139.281322 \nL 196.437307 139.281322 \nL 197.046034 138.921917 \nL 197.654761 138.832066 \nL 198.872216 138.292959 \nL 199.480943 138.292959 \nL 200.08967 137.664 \nL 200.698398 136.765488 \nL 201.915852 135.597421 \nL 203.133307 134.609058 \nL 203.742034 133.800397 \nL 204.350761 133.890248 \nL 206.176943 132.632331 \nL 207.394398 131.194711 \nL 208.003125 131.10486 \nL 208.611852 130.475901 \nL 209.829307 129.66724 \nL 210.438034 129.66724 \nL 211.046761 129.307835 \nL 211.655489 128.409322 \nL 212.264216 127.780364 \nL 212.872943 127.600661 \nL 213.48167 127.690512 \nL 214.699125 126.792 \nL 216.525307 126.252893 \nL 217.134034 126.702149 \nL 217.742761 126.07319 \nL 218.351489 125.803636 \nL 218.960216 125.803636 \nL 219.568943 125.35438 \nL 220.17767 125.623934 \nL 220.786398 125.713785 \nL 221.395125 125.623934 \nL 222.61258 124.455868 \nL 223.221307 124.815273 \nL 225.047489 124.455868 \nL 225.656216 124.276165 \nL 226.264943 124.725421 \nL 226.87367 124.994975 \nL 227.482398 125.623934 \nL 228.091125 125.713785 \nL 228.699852 125.534083 \nL 229.30858 124.905124 \nL 229.917307 124.994975 \nL 230.526034 124.455868 \nL 231.134761 124.276165 \nL 231.743489 124.366017 \nL 232.352216 124.63557 \nL 232.960943 124.276165 \nL 233.56967 124.096463 \nL 234.178398 123.557355 \nL 235.395852 122.029884 \nL 237.830761 120.23286 \nL 238.439489 120.053157 \nL 239.048216 119.244496 \nL 240.26567 118.79524 \nL 240.874398 118.615537 \nL 241.483125 119.154645 \nL 242.70058 119.603901 \nL 243.309307 119.154645 \nL 243.918034 119.783603 \nL 244.526761 119.244496 \nL 245.135489 119.424198 \nL 245.744216 118.525686 \nL 246.352943 117.986579 \nL 247.570398 117.447471 \nL 248.179125 117.35762 \nL 248.787852 117.447471 \nL 250.614034 116.189554 \nL 251.222761 115.92 \nL 252.440216 115.650446 \nL 253.048943 115.830149 \nL 253.65767 115.560595 \nL 254.266398 115.111339 \nL 255.483852 115.021488 \nL 256.09258 115.380893 \nL 256.701307 115.20119 \nL 257.310034 114.572231 \nL 257.918761 114.122975 \nL 258.527489 113.494017 \nL 259.136216 113.224463 \nL 259.744943 113.224463 \nL 260.35367 112.954909 \nL 260.962398 112.865058 \nL 261.571125 113.314314 \nL 262.78858 113.134612 \nL 264.614761 114.302678 \nL 265.223489 113.853421 \nL 265.832216 113.76357 \nL 266.440943 113.314314 \nL 267.04967 113.134612 \nL 267.658398 113.583868 \nL 268.267125 113.76357 \nL 268.875852 112.954909 \nL 269.48458 112.685355 \nL 270.093307 112.595504 \nL 270.702034 111.876694 \nL 271.310761 111.696992 \nL 271.919489 111.696992 \nL 272.528216 112.056397 \nL 273.136943 112.056397 \nL 273.74567 112.32595 \nL 274.963125 111.966545 \nL 275.571852 112.236099 \nL 276.18058 111.696992 \nL 277.398034 111.60714 \nL 278.006761 111.068033 \nL 279.224216 111.157884 \nL 280.44167 110.169521 \nL 281.050398 109.271008 \nL 281.659125 109.001455 \nL 282.267852 109.540562 \nL 282.87658 109.091306 \nL 283.485307 109.630413 \nL 284.094034 109.001455 \nL 285.311489 108.282645 \nL 285.920216 107.743537 \nL 286.528943 106.934876 \nL 287.13767 106.755174 \nL 287.746398 106.755174 \nL 288.355125 106.48562 \nL 288.963852 106.036364 \nL 289.57258 106.126215 \nL 290.181307 106.036364 \nL 291.398761 106.845025 \nL 292.007489 106.036364 \nL 292.616216 106.036364 \nL 293.224943 105.676959 \nL 293.83367 105.676959 \nL 294.442398 105.048 \nL 295.051125 105.048 \nL 295.659852 105.407405 \nL 296.26858 105.137851 \nL 297.486034 104.958149 \nL 298.094761 104.598744 \nL 298.703489 104.419041 \nL 299.312216 104.778446 \nL 299.920943 104.508893 \nL 301.138398 104.868298 \nL 301.747125 104.868298 \nL 302.355852 103.790083 \nL 302.96458 103.161124 \nL 303.573307 102.17276 \nL 304.182034 101.633653 \nL 306.008216 102.352463 \nL 306.616943 102.442314 \nL 307.22567 102.711868 \nL 308.443125 102.262612 \nL 309.051852 101.813355 \nL 309.66058 100.824992 \nL 310.269307 100.555438 \nL 310.878034 100.73514 \nL 311.486761 100.555438 \nL 312.095489 100.645289 \nL 312.704216 100.375736 \nL 313.312943 100.555438 \nL 314.530398 99.387372 \nL 315.139125 99.027967 \nL 315.747852 98.039603 \nL 316.35658 97.859901 \nL 316.965307 97.500496 \nL 317.574034 96.781686 \nL 318.182761 96.512132 \nL 318.791489 96.422281 \nL 319.400216 95.973025 \nL 320.008943 96.152727 \nL 320.61767 95.973025 \nL 321.226398 95.344066 \nL 321.835125 95.433917 \nL 323.05258 95.074512 \nL 323.661307 94.355702 \nL 324.270034 93.816595 \nL 325.487489 93.007934 \nL 326.096216 92.558678 \nL 326.704943 93.367339 \nL 327.31367 93.726744 \nL 327.922398 93.816595 \nL 328.531125 92.828231 \nL 329.139852 92.828231 \nL 329.74858 92.648529 \nL 330.357307 92.73838 \nL 330.966034 92.558678 \nL 331.574761 93.097785 \nL 332.183489 92.109421 \nL 332.792216 92.289124 \nL 333.400943 91.839868 \nL 334.00967 91.121058 \nL 334.618398 90.58195 \nL 335.227125 91.390612 \nL 335.835852 91.390612 \nL 336.44458 91.031207 \nL 337.662034 90.851504 \nL 338.270761 90.222545 \nL 338.879489 89.324033 \nL 339.488216 89.503736 \nL 340.096943 88.874777 \nL 340.70567 88.695074 \nL 341.314398 89.324033 \nL 341.923125 90.402248 \nL 342.531852 90.312397 \nL 343.14058 89.593587 \nL 343.749307 89.683438 \nL 345.575489 88.874777 \nL 346.792943 89.503736 \nL 347.40167 90.402248 \nL 348.010398 89.773289 \nL 348.619125 90.132694 \nL 349.227852 89.144331 \nL 349.83658 89.324033 \nL 350.445307 88.784926 \nL 351.054034 89.144331 \nL 351.662761 88.695074 \nL 352.271489 87.527008 \nL 352.880216 87.976264 \nL 353.488943 88.155967 \nL 354.09767 88.155967 \nL 354.706398 87.886413 \nL 355.923852 87.796562 \nL 356.53258 87.167603 \nL 357.141307 87.527008 \nL 357.750034 87.437157 \nL 358.358761 87.167603 \nL 358.967489 87.886413 \nL 359.576216 87.257455 \nL 359.576216 87.257455 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe61f54c067\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"40.603125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.hlines(13, 0, len(score_list), colors='red', linestyles='dashed', label='12 pts', zorder=15)\n",
    "plt.plot(np.arange(len(score_list)), score_list, zorder=5)\n",
    "plt.plot(np.arange(len(score_list)), score_trailing_avg_list, zorder=20)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('drl-torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "212389a35b01702f59833779e07d764f9721fa361a14aad1c92745fe43c8de59"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}